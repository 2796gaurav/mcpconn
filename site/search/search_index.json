{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to mcpconn","text":"<p>mcpconn is a Python library that provides a simple and efficient way to connect your applications to AI models using the Multi-purpose Cooperative Protocol (MCP). It acts as a wrapper around the <code>mcp</code> library, offering a streamlined client interface for seamless integration with various AI providers and transport protocols.</p> <p> </p>"},{"location":"#features","title":"\u2728 Features","text":"<ul> <li>Simplified Client Interface: A high-level <code>mcpconn</code> for easy interaction with MCP servers.</li> <li>Multi-provider Support: Out-of-the-box support for Anthropic and OpenAI models.</li> <li>Flexible Transports: Connect to servers using STDIO, SSE, or Streamable HTTP.</li> <li>Built-in Guardrails: Protect your application with content filtering, PII masking, and injection detection.</li> <li>Conversation Management: Easily manage conversation history, context, and persistence.</li> <li>Asynchronous by Design: Built with <code>asyncio</code> for high-performance, non-blocking I/O.</li> <li>Extensible: Easily add new LLM providers, transports, or guardrails.</li> </ul> <p>Ready to dive in? Check out the Getting Started guide. </p>"},{"location":"api-reference/","title":"API Reference","text":"<p>This page provides a reference for the <code>mcpconn</code> library's public API.</p>"},{"location":"api-reference/#mcpconn","title":"<code>mcpconn</code>","text":"<p>The <code>mcpconn</code> is the main entry point for interacting with MCP servers.</p> <p>::: mcpconn.MCPClient     options:       show_root_heading: true       show_source: false</p>"},{"location":"api-reference/#__init__","title":"<code>__init__</code>","text":"<p>Initializes the MCP client.</p> <p>Parameters:</p> <ul> <li><code>llm_provider</code> (str): The LLM provider to use. Currently supports <code>\"anthropic\"</code> and <code>\"openai\"</code>. Defaults to <code>\"anthropic\"</code>.</li> <li><code>env_file</code> (str, optional): Path to a <code>.env</code> file to load environment variables from.</li> <li><code>timeout</code> (float): Default timeout in seconds for operations. Defaults to <code>30.0</code>.</li> <li><code>conversation_id</code> (str, optional): An existing conversation ID to resume.</li> <li><code>auto_generate_ids</code> (bool): Whether to automatically generate a unique conversation ID for each message if one isn't active. Defaults to <code>True</code>.</li> <li><code>**llm_kwargs</code>: Additional keyword arguments to pass to the LLM provider's constructor.</li> </ul>"},{"location":"api-reference/#connect","title":"<code>connect</code>","text":"<p>Connects to an MCP server.</p> <p>Parameters:</p> <ul> <li><code>connection_string</code> (str): The connection string for the server (e.g., a URL for HTTP, or a command for STDIO).</li> <li><code>transport</code> (str, optional): The transport protocol to use (<code>\"stdio\"</code>, <code>\"sse\"</code>, <code>\"http\"</code>). If <code>None</code>, it's inferred from the connection string.</li> <li><code>headers</code> (dict, optional): A dictionary of headers to use for HTTP-based transports.</li> </ul>"},{"location":"api-reference/#query","title":"<code>query</code>","text":"<p>Sends a message to the AI and gets a response.</p> <p>Parameters:</p> <ul> <li><code>message</code> (str): The message to send.</li> <li><code>max_iterations</code> (int): The maximum number of tool-use iterations to perform. Defaults to <code>5</code>.</li> <li><code>conversation_id</code> (str, optional): The ID of the conversation to use for this query.</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: The AI's response.</li> </ul>"},{"location":"api-reference/#conversation-management","title":"Conversation Management","text":""},{"location":"api-reference/#start_conversation","title":"<code>start_conversation</code>","text":"<p>Starts a new conversation or resumes an existing one.</p> <p>Parameters:</p> <ul> <li><code>conversation_id</code> (str, optional): The ID of the conversation to start or resume. If <code>None</code>, a new one is generated.</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: The active conversation ID.</li> </ul>"},{"location":"api-reference/#get_conversation_history","title":"<code>get_conversation_history</code>","text":"<p>Retrieves the message history for the current conversation.</p> <p>Returns:</p> <ul> <li><code>list</code>: A list of message dictionaries.</li> </ul>"},{"location":"api-reference/#save_conversation-load_conversation","title":"<code>save_conversation</code> / <code>load_conversation</code>","text":"<p>Saves the current conversation state to a file or loads it from a file.</p> <p>Parameters:</p> <ul> <li><code>filepath</code> (str): The path to the file.</li> </ul>"},{"location":"api-reference/#guardrails","title":"Guardrails","text":""},{"location":"api-reference/#add_guardrail","title":"<code>add_guardrail</code>","text":"<p>Adds a guardrail to the client for content moderation.</p> <p>Parameters:</p> <ul> <li><code>guardrail</code>: An instance of a guardrail class (e.g., <code>WordMaskGuardrail</code>). </li> </ul>"},{"location":"code-of-conduct/","title":"Code of Conduct","text":""},{"location":"code-of-conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that are professional, respectful, and welcoming.</p>"},{"location":"code-of-conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes,   and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the   overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or   advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email   address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a   professional setting</li> </ul>"},{"location":"code-of-conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"code-of-conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"code-of-conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at 2796gaurav@gmail.com. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"code-of-conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"code-of-conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"code-of-conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interaction in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"code-of-conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the. All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"code-of-conduct/#enforcement-guidelines_1","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"code-of-conduct/#1-correction_1","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"code-of-conduct/#2-warning_1","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interaction in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"code-of-conduct/#3-temporary-ban_1","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"code-of-conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"code-of-conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.0, available at https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.</p>"},{"location":"core-concepts/","title":"Core Concepts","text":"<p>This page explains the key concepts behind <code>mcpconn</code> and the protocol it is built upon.</p>"},{"location":"core-concepts/#the-multi-purpose-cooperative-protocol-mcp","title":"The Multi-purpose Cooperative Protocol (MCP)","text":"<p>At its heart, <code>mcpconn</code> is designed to simplify interactions with servers that use the Model Context Protocol (MCP). MCP is a standardized protocol that creates a common ground for different AI models (like those from Anthropic or OpenAI) and the applications that use them.</p> <p>Think of it as a universal adapter for AI. Instead of writing custom code to handle the specific API of each AI provider, you can connect to an MCP-compliant server that handles those details for you.</p> <p>The key benefits of this approach are:</p> <ul> <li>Provider Agnostic: You can switch between different AI providers with minimal code changes, often just by changing a parameter in the client.</li> <li>Standardized Tool Use: MCP defines a standard way for AI models to request the use of external tools (like a weather API, a calculator, or a database). Your application can expose these tools to the AI in a consistent way.</li> <li>Simplified Communication: The protocol handles the complexities of streaming responses, managing conversation history, and handling different data formats.</li> </ul>"},{"location":"core-concepts/#how-mcpconn-helps","title":"How <code>mcpconn</code> Helps","text":"<p>While MCP provides the standard, <code>mcpconn</code> provides the convenience. It acts as a high-level client library that abstracts away the low-level details of the protocol.</p> <p>Instead of manually constructing MCP messages, you can use the intuitive methods on the <code>mcpconn</code>:</p> <ul> <li><code>client.connect()</code>: Handles establishing the connection over different transports (like STDIO or HTTP).</li> <li><code>client.query()</code>: Sends a message to the AI and automatically handles the back-and-forth of tool usage.</li> <li><code>client.start_conversation()</code>: Manages session IDs and history.</li> </ul> <p>By using <code>mcpconn</code>, you can focus on building your application's logic instead of worrying about the intricacies of AI integration. </p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you get up and running with <code>mcpconn</code>.</p>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>To install <code>mcpconn</code>, run the following command in your terminal:</p> <pre><code>pip install mcpconn\n</code></pre> <p>This will install the core library and its dependencies.</p>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":"<p>Here's a simple example of how to use <code>mcpconn</code> to connect to an MCP server and interact with an AI model:</p> <pre><code>import asyncio\nfrom mcpconn import MCPClient\n\nasync def main():\n    # Connect to a local server using STDIO\n    client = MCPClient(llm_provider=\"anthropic\")\n    await client.connect(\"python examples/simple_server/weather_stdio.py\")\n\n    # Start a conversation\n    conversation_id = client.start_conversation()\n    print(f\"Started conversation: {conversation_id}\")\n\n    # Send a message and get a response\n    response = await client.query(\"Hello, world!\")\n    print(f\"AI: {response}\")\n\n    # Disconnect from the server\n    await client.disconnect()\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre> <p>This example demonstrates the basic workflow:</p> <ol> <li>Import <code>mcpconn</code>: The main entry point for interacting with the library.</li> <li>Instantiate the client: Create an instance of <code>mcpconn</code>, specifying the desired LLM provider.</li> <li>Connect to a server: Use <code>await client.connect()</code> to establish a connection.</li> <li>Interact with the AI: Use methods like <code>start_conversation()</code> and <code>query()</code> to have a conversation.</li> <li>Disconnect: Cleanly close the connection with <code>await client.disconnect()</code>.</li> </ol> <p>For more detailed examples, please refer to the <code>examples</code> directory in the project repository. </p>"},{"location":"guardrails/","title":"Using Guardrails","text":"<p><code>mcpconn</code> comes with a powerful, built-in guardrail system to help you secure your application and moderate content. Guardrails can inspect both user input before it's sent to the AI and the AI's response before it's sent to the user.</p>"},{"location":"guardrails/#how-it-works","title":"How it Works","text":"<p>The <code>mcpconn</code> has a <code>GuardrailManager</code> that can hold multiple guardrails. You can add any of the built-in guardrails or even create your own.</p> <p>When you call <code>client.query()</code>, the following happens: 1. The user's message is checked against all registered guardrails. 2. If a guardrail detects an issue and provides masked content (e.g., <code>[REDACTED]</code>), the message is sanitized before being sent to the AI. 3. After the AI responds, its message is also checked against all guardrails. 4. If the response is flagged, it can be masked or blocked entirely before being returned to your application.</p>"},{"location":"guardrails/#example-usage","title":"Example Usage","text":"<p>Here is a complete example of how to add and use multiple guardrails.</p> <pre><code>import asyncio\nfrom mclpclient import mcpconn\nfrom mcpconn.guardrails import PIIGuardrail, WordMaskGuardrail, InjectionGuardrail\n\nasync def main():\n    client = mcpconn(llm_provider=\"openai\")\n\n    # Add a guardrail to detect and mask PII\n    client.add_guardrail(PIIGuardrail(name=\"pii_detector\"))\n\n    # Add a guardrail to block specific sensitive words\n    client.add_guardrail(WordMaskGuardrail(\n        name=\"word_mask\",\n        words_to_mask=[\"secret\", \"confidential\"],\n        replacement=\"[CENSORED]\"\n    ))\n\n    # Add a guardrail to detect common injection attacks\n    client.add_guardrail(InjectionGuardrail(name=\"injection_detector\"))\n\n    # This message contains PII and a masked word\n    user_message = \"Hi, my name is John Doe and my email is john.doe@example.com. This is a secret.\"\n    print(f\"Original message: {user_message}\")\n\n    # The client will automatically apply the guardrails\n    # NOTE: For this example, we aren't connecting to a real server\n    # We are demonstrating the guardrail check on the input message\n\n    guardrail_results = await client.guardrails.check_all(user_message)\n\n    final_message = user_message\n    for result in guardrail_results:\n        if not result.passed:\n            print(f\"Guardrail '{result.message}' failed.\")\n            if result.masked_content:\n                final_message = result.masked_content\n\n    print(f\"Sanitized message: {final_message}\")\n\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre>"},{"location":"guardrails/#available-guardrails","title":"Available Guardrails","text":""},{"location":"guardrails/#piiguardrail","title":"<code>PIIGuardrail</code>","text":"<p>Detects and masks common Personally Identifiable Information (PII). - Finds: Email addresses, phone numbers, SSNs, and credit card numbers. - Action: Replaces found PII with <code>[REDACTED]</code>.</p>"},{"location":"guardrails/#wordmaskguardrail","title":"<code>WordMaskGuardrail</code>","text":"<p>Masks a custom list of words or phrases. - Configuration:   - <code>words_to_mask</code>: A list of strings to find.   - <code>replacement</code>: The string to replace them with. - Action: Replaces found words with the replacement string.</p>"},{"location":"guardrails/#responseblockguardrail","title":"<code>ResponseBlockGuardrail</code>","text":"<p>Blocks a response entirely if it contains certain words and replaces it with a standardized message. This is most useful for moderating AI output. - Configuration:   - <code>blocked_words</code>: A list of strings that will trigger the block.   - <code>standardized_response</code>: The message to return instead. - Action: If a blocked word is found, the original response is discarded and the standardized response is returned.</p>"},{"location":"guardrails/#injectionguardrail","title":"<code>InjectionGuardrail</code>","text":"<p>Detects common patterns associated with injection attacks. - Finds: Cross-Site Scripting (XSS), SQL injection, shell injection, and path traversal patterns. - Action: Fails the check if a potential attack is detected. Does not mask content by default, as the entire input should likely be rejected. </p>"},{"location":"license/","title":"License","text":"<pre><code>MIT License\n\nCopyright (c) 2024 Gaurav Chauhan\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n</code></pre>"}]}